{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import math \n",
    "import os\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for remove comma within numbers\n",
    "def removeCommas(string): \n",
    "    string = string.replace(',','')\n",
    "    return string "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap data from worldmeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if we can scrap info from worldometers\n",
    "# The communication with website is ok if the response is 200\n",
    "headers = ({'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "worldometers = \"https://www.worldometers.info/coronavirus/#countries\"\n",
    "response = get(worldometers, headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scrap all content from the website\n",
    "html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# After inspect the website content, data are stored inside tag 'tbody' and table header is 'thead'\n",
    "table_contents = html_soup.find_all('tbody')\n",
    "table_header = html_soup.find_all('thead')\n",
    "\n",
    "# Header for the table\n",
    "header = []\n",
    "for head_title in table_header[0].find_all('th'):    \n",
    "    header.append(str(head_title.contents))\n",
    "\n",
    "# Save value into columns\n",
    "CountryName = []\n",
    "TotalCases = []\n",
    "NewCases = []\n",
    "TotalDeaths = []\n",
    "NewDeaths = []\n",
    "TotalRecovered = []\n",
    "ActiveCases = []\n",
    "SeriousCritical = []\n",
    "\n",
    "for row in table_contents[0].find_all('tr'):\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells[0].find_all('a')) >= 1:\n",
    "        CountryName.append(cells[0].find_all('a')[0].contents[0])\n",
    "    elif len(cells[0].find_all('span')) >= 1:\n",
    "        CountryName.append(cells[0].find_all('span')[0].contents[0])   \n",
    "    else:\n",
    "        CountryName.append(cells[0].contents[0])\n",
    "    \n",
    "    \n",
    "    if len(cells[1].contents) >=1:\n",
    "        TotalCases.append(cells[1].contents[0])\n",
    "    else:\n",
    "        TotalCases.append(0)\n",
    "    \n",
    "    if len(cells[2].contents) >= 1:\n",
    "        NewCases.append(cells[2].contents[0])\n",
    "    else:\n",
    "        NewCases.append(0)\n",
    "        \n",
    "    \n",
    "    if len(cells[3].contents) >= 1:\n",
    "        TotalDeaths.append(cells[3].contents[0])\n",
    "    else:\n",
    "        TotalDeaths.append(0)\n",
    "\n",
    "    \n",
    "    if len(cells[4].contents) >= 1:\n",
    "        NewDeaths.append(cells[4].contents[0])\n",
    "    else:\n",
    "        NewDeaths.append(0)\n",
    "    \n",
    "    if len(cells[5].contents) >= 1:\n",
    "        TotalRecovered.append(cells[5].contents[0])\n",
    "    else:\n",
    "        TotalRecovered.append(0)\n",
    "        \n",
    "    if len(cells[6].contents) >= 1:\n",
    "        ActiveCases.append(cells[6].contents[0])\n",
    "    else:\n",
    "        ActiveCases.append(0)\n",
    "    \n",
    "    if len(cells[7].contents) >= 1:\n",
    "        SeriousCritical.append(cells[7].contents[0])\n",
    "    else:\n",
    "        SeriousCritical.append(0)\n",
    "        \n",
    "        \n",
    "CaseTable = pd.DataFrame({header[0]: CountryName,\n",
    "                          header[1]: TotalCases,\n",
    "                          header[2]: NewCases,\n",
    "                          header[3]: TotalDeaths,\n",
    "                          header[4]: NewDeaths,                          \n",
    "                          header[5]: TotalRecovered,\n",
    "                          header[6]: ActiveCases,\n",
    "                          header[7]: SeriousCritical,\n",
    "                          })  \n",
    "\n",
    "# CaseTable.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseTableSimple = CaseTable[[CaseTable.columns[0], CaseTable.columns[1], CaseTable.columns[3], CaseTable.columns[5]]]\n",
    "caseTableSimple.columns = ['Country/Region', 'Confirmed', 'Deaths', 'Recovered']\n",
    "# Set data type as string first for manuipulation\n",
    "caseTableSimple = caseTableSimple.astype({'Country/Region':str,'Confirmed':str,'Deaths':str, 'Recovered':str})\n",
    "# Remove the last row of total number (changed on 20200310, worldmeter moved this row as next tbody)\n",
    "#caseTableSimple = caseTableSimple.iloc[:-1,:]\n",
    "# Remove lead and tail space for each element\n",
    "caseTableSimple = caseTableSimple.apply(lambda x: x.str.strip())\n",
    "# Remove comma for each element\n",
    "caseTableSimple = caseTableSimple.applymap(removeCommas)\n",
    "# Replace empty str with zero. This include row of 'Diamond Princess' (its name is empty)\n",
    "caseTableSimple = caseTableSimple.replace('', '0')\n",
    "# After string manipulation, convert data type as correct type\n",
    "caseTableSimple = caseTableSimple.astype({'Country/Region':'str',\n",
    "                                          'Confirmed':'int',\n",
    "                                          'Deaths':'int',\n",
    "                                          'Recovered':'int',                                          \n",
    "                                         })\n",
    "# Data for these countries come from other source\n",
    "removeRegion = []\n",
    "for i in removeRegion:\n",
    "    caseTableSimple.drop(caseTableSimple[caseTableSimple['Country/Region'] == i].index, axis=0, inplace=True)\n",
    "\n",
    "# Change Country name the same as my old data \n",
    "if 'S. Korea' in list(caseTableSimple['Country/Region']):\n",
    "    caseTableSimple = caseTableSimple.replace('S. Korea', 'South Korea')\n",
    "\n",
    "# Add column 'Province/State' with empty value\n",
    "caseTableSimple['Province/State'] =''\n",
    "\n",
    "# In my old data, 'Diamond Princess' is represented by 'Yokohama' in the column of 'Province/State'\n",
    "if 'Diamond Princess' in list(caseTableSimple['Country/Region']):\n",
    "    caseTableSimple.at[caseTableSimple.loc[caseTableSimple['Country/Region'] == 'Diamond Princess',].index, 'Province/State'] = 'Yokohama'\n",
    "    caseTableSimple['Country/Region'].replace({'Diamond Princess':'Japan'}, inplace=True)\n",
    "\n",
    "# In my old data, 'Belgium' has 'Brussels' in the column of 'Province/State'\n",
    "if 'Belgium' in list(caseTableSimple['Country/Region']):\n",
    "    caseTableSimple.at[caseTableSimple.loc[caseTableSimple['Country/Region'] == 'Belgium',].index, 'Province/State'] = 'Brussels'\n",
    "\n",
    "# In my old data, I used 'Macau' not 'Macao'\n",
    "if 'Macao' in list(caseTableSimple['Country/Region']):\n",
    "    caseTableSimple.at[caseTableSimple.loc[caseTableSimple['Country/Region'] == 'Macao',].index, 'Province/State'] = 'Macau'\n",
    "    caseTableSimple['Country/Region'].replace({'Macao':'Macau'}, inplace=True)\n",
    "\n",
    "# In my old data, 'Hong Kong' has 'Hong Kong' in the column of 'Province/State'\n",
    "if 'Hong Kong' in list(caseTableSimple['Country/Region']):\n",
    "    caseTableSimple.at[caseTableSimple.loc[caseTableSimple['Country/Region'] == 'Hong Kong',].index, 'Province/State'] = 'Hong Kong'\n",
    "\n",
    "# In my old data, 'Taiwan' has 'Taiwan' in the column of 'Province/State'\n",
    "if 'Taiwan' in list(caseTableSimple['Country/Region']):\n",
    "    caseTableSimple.at[caseTableSimple.loc[caseTableSimple['Country/Region'] == 'Taiwan',].index, 'Province/State'] = 'Taiwan'\n",
    "\n",
    "# In my old data, I used 'United Arab Emirates' not 'UAE'\n",
    "if 'UAE' in list(caseTableSimple['Country/Region']):\n",
    "    caseTableSimple['Country/Region'].replace({'UAE':'United Arab Emirates'}, inplace=True)\n",
    "\n",
    "if 'Réunion' in list(caseTableSimple['Country/Region']):\n",
    "    caseTableSimple['Country/Region'].replace({'Réunion':'Reunion'}, inplace=True)\n",
    "    \n",
    "if 'Curaçao' in list(caseTableSimple['Country/Region']):\n",
    "    caseTableSimple['Country/Region'].replace({'Curaçao':'Curacao'}, inplace=True)\n",
    "\n",
    "# In my old data I used US time as Last Update time\n",
    "currentTime = datetime.now()\n",
    "lastUpdateTime = currentTime.strftime('%m/%d/%Y %H:%M')\n",
    "# Remove the first number (This only works for month number less than 10)\n",
    "lastUpdateTime[1:]\n",
    "caseTableSimple['Last Update'] = lastUpdateTime[1:]\n",
    "\n",
    "# Reorder list as all old data\n",
    "columnList = caseTableSimple.columns.tolist()\n",
    "columnList =[columnList[i] for i in [4, 0, 5, 1, 2, 3]]\n",
    "caseTableSimple = caseTableSimple[columnList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTable = caseTableSimple.copy()\n",
    "# finalTable\n",
    "\n",
    "\n",
    "\n",
    "finalTable['Confirmed'] = finalTable['Confirmed'].fillna(0).astype(int)\n",
    "finalTable['Deaths'] = finalTable['Deaths'].fillna(0).astype(int)\n",
    "finalTable['Recovered'] = finalTable['Recovered'].fillna(0).astype(int)\n",
    "\n",
    "mask = ((finalTable['Country/Region'].notnull()) | (finalTable['Province/State'].notnull()) | (finalTable['Last Update'].notnull()) |\n",
    "        (finalTable['Recovered'].notnull()) | (finalTable['Deaths'].notnull()) | (finalTable['Confirmed']))\n",
    "finalTable = finalTable[mask]\n",
    "\n",
    "finalTable['Country/Region'] = finalTable['Country/Region'].replace('USA','US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeStampe = currentTime.strftime('%m_%d_%Y_%H_%M')\n",
    "finalTable.to_csv('../data/web_data/{}_webData.csv'.format(timeStampe), index=False)\n",
    "finalTable.to_csv('../data/web_data/last_capure.csv', index=False)\n",
    "\n",
    "date_time = currentTime.strftime('%Y-%m-%d-%H-%M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('../data/web_data/last_capure.csv')\n",
    "new_data = new_data.groupby(by=['Country/Region','Last Update'], as_index=False).sum()\n",
    "\n",
    "date_day = timeStampe = currentTime.strftime('%Y-%m-%d')\n",
    "\n",
    "new_data['date'] = date_day\n",
    "\n",
    "new_data = new_data.rename(columns={'Country/Region':'countryname','Last Update':'Date_last_updated_AEDT'})\n",
    "\n",
    "\n",
    "cols = ['Date_last_updated_AEDT', 'date', 'countryname', 'Confirmed', 'Deaths', 'Recovered']\n",
    "new_data = new_data[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_last_updated_AEDT</th>\n",
       "      <th>date</th>\n",
       "      <th>countryname</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>China</td>\n",
       "      <td>81218</td>\n",
       "      <td>3281</td>\n",
       "      <td>73650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Italy</td>\n",
       "      <td>74386</td>\n",
       "      <td>7503</td>\n",
       "      <td>9362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>US</td>\n",
       "      <td>64765</td>\n",
       "      <td>909</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Spain</td>\n",
       "      <td>47611</td>\n",
       "      <td>3445</td>\n",
       "      <td>5367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Germany</td>\n",
       "      <td>37323</td>\n",
       "      <td>206</td>\n",
       "      <td>3547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Iran</td>\n",
       "      <td>27017</td>\n",
       "      <td>2077</td>\n",
       "      <td>9625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>France</td>\n",
       "      <td>25233</td>\n",
       "      <td>1331</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>10897</td>\n",
       "      <td>153</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>9137</td>\n",
       "      <td>126</td>\n",
       "      <td>3730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>UK</td>\n",
       "      <td>8264</td>\n",
       "      <td>435</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>6412</td>\n",
       "      <td>356</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Austria</td>\n",
       "      <td>5588</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>4937</td>\n",
       "      <td>178</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Canada</td>\n",
       "      <td>3290</td>\n",
       "      <td>30</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Norway</td>\n",
       "      <td>3066</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>2995</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>2526</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3/25/2020 17:32</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2433</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date_last_updated_AEDT        date  countryname  Confirmed  Deaths  \\\n",
       "0         3/25/2020 17:32  2020-03-25        China      81218    3281   \n",
       "1         3/25/2020 17:32  2020-03-25        Italy      74386    7503   \n",
       "2         3/25/2020 17:32  2020-03-25           US      64765     909   \n",
       "3         3/25/2020 17:32  2020-03-25        Spain      47611    3445   \n",
       "4         3/25/2020 17:32  2020-03-25      Germany      37323     206   \n",
       "5         3/25/2020 17:32  2020-03-25         Iran      27017    2077   \n",
       "6         3/25/2020 17:32  2020-03-25       France      25233    1331   \n",
       "7         3/25/2020 17:32  2020-03-25  Switzerland      10897     153   \n",
       "8         3/25/2020 17:32  2020-03-25  South Korea       9137     126   \n",
       "9         3/25/2020 17:32  2020-03-25           UK       8264     435   \n",
       "10        3/25/2020 17:32  2020-03-25  Netherlands       6412     356   \n",
       "11        3/25/2020 17:32  2020-03-25      Austria       5588      30   \n",
       "12        3/25/2020 17:32  2020-03-25      Belgium       4937     178   \n",
       "13        3/25/2020 17:32  2020-03-25       Canada       3290      30   \n",
       "14        3/25/2020 17:32  2020-03-25       Norway       3066      14   \n",
       "15        3/25/2020 17:32  2020-03-25     Portugal       2995      43   \n",
       "16        3/25/2020 17:32  2020-03-25       Sweden       2526      44   \n",
       "17        3/25/2020 17:32  2020-03-25       Brazil       2433      57   \n",
       "\n",
       "    Recovered  \n",
       "0       73650  \n",
       "1        9362  \n",
       "2         393  \n",
       "3        5367  \n",
       "4        3547  \n",
       "5        9625  \n",
       "6        3900  \n",
       "7         131  \n",
       "8        3730  \n",
       "9         135  \n",
       "10          3  \n",
       "11          9  \n",
       "12        547  \n",
       "13        185  \n",
       "14          6  \n",
       "15         22  \n",
       "16         16  \n",
       "17          2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.sort_values(by='Confirmed', ascending=False).reset_index(drop=True).head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_data = pd.read_csv('../data/cumulative_data/covid_last.csv')\n",
    "mask = last_data['date']!=date_day\n",
    "last_data = last_data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat([new_data,last_data],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('../data/cumulative_data/{}.csv'.format(date_time), index=False)\n",
    "final_data.to_csv('../data/cumulative_data/covid_last.csv'.format(date_time), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# last_data['Date_last_updated_AEDT'] = pd.DatetimeIndex(last_data['Date_last_updated_AEDT']) - pd.DateOffset(1)\n",
    "# last_data['date'] = pd.DatetimeIndex(last_data['date']) - pd.DateOffset(1)\n",
    "\n",
    "# last_data[cols].to_csv('../data/cumulative_data/covid_last.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap data for US_CAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if we can scrap info from worldometers\n",
    "# The communication with website is ok if the response is 200\n",
    "US_Canada = \"https://coronavirus.1point3acres.com/zh\"\n",
    "response2 = get(US_Canada, headers=headers)\n",
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap all content from the website\n",
    "html_soup2 = BeautifulSoup(response2.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since they change class index everyday, this code is for finding the new index.\n",
    "indexList = []\n",
    "for span in html_soup2.find_all('span'):\n",
    "    # Only retain 'span' that has contents\n",
    "    if len(span.contents):\n",
    "        # Since we only need to find index for table, use one of the table head as target word to locate index\n",
    "        if span.contents[0] == 'Location':\n",
    "            # Store the index inside a list\n",
    "            indexList.append(span['class'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first index is for US table and the 2nd index is for Canada table. Do not casr about the rest inside the list.\n",
    "USindex, CANindex, _ = indexList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the index return right data\n",
    "# html_soup2.find_all('span', class_=USindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# html_soup2.find_all('span', class_=CANindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(html_soup2.find_all('span', class_=CANindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Locations = []\n",
    "Confirmed = []\n",
    "Recovered = []\n",
    "Deaths = []\n",
    "list1 = range(1, len(html_soup2.find_all('span', class_=USindex))-4, 5)\n",
    "list2 = range(2, len(html_soup2.find_all('span', class_=USindex))-3, 5)\n",
    "list3 = range(3, len(html_soup2.find_all('span', class_=USindex))-2, 5)\n",
    "list4 = range(4, len(html_soup2.find_all('span', class_=USindex))-1, 5)\n",
    "\n",
    "for index in list1:\n",
    "    if len(html_soup2.find_all('span', class_=USindex)[index].contents):\n",
    "        Locations.append(html_soup2.find_all('span', class_=USindex)[index].contents[0])\n",
    "    else:\n",
    "        Locations.append(0)\n",
    "for index in list2:\n",
    "    if len(html_soup2.find_all('span', class_=USindex)[index].contents):\n",
    "        Confirmed.append(html_soup2.find_all('span', class_=USindex)[index].contents[0])\n",
    "    else:\n",
    "        Confirmed.append(0)\n",
    "for index in list3:\n",
    "    # They do not provide recovered cases number anymore.\n",
    "    #if len(html_soup2.find_all('span', class_=USindex)[index].contents):\n",
    "    #    Recovered.append(html_soup2.find_all('span', class_=USindex)[index].contents[0])\n",
    "    #else:\n",
    "    Recovered.append(0)\n",
    "for index in list3:\n",
    "    if len(html_soup2.find_all('span', class_=USindex)[index].contents):\n",
    "        Deaths.append(html_soup2.find_all('span', class_=USindex)[index].contents[0])\n",
    "    else:\n",
    "        Deaths.append(0)\n",
    "    \n",
    "US_data = pd.DataFrame({'Province/State':Locations,\n",
    "                        'Confirmed':Confirmed,\n",
    "                        'Deaths':Deaths,\n",
    "                        #'Recovered':Recovered,  \n",
    "                            })\n",
    "\n",
    "# Remove rows that are not data\n",
    "US_data.drop(US_data[US_data['Deaths'] == 'Deaths'].index, axis=0, inplace=True)\n",
    "\n",
    "# Replace Washington, D.C. as Washington DC\n",
    "if 'Washington, D.C.' in list(US_data['Province/State']):\n",
    "    US_data['Province/State'].replace({'Washington, D.C.':'Washington DC'}, inplace=True)\n",
    "\n",
    "# Replace Washington as WA\n",
    "if 'Washington' in list(US_data['Province/State']):\n",
    "    US_data['Province/State'].replace({'Washington':'WA'}, inplace=True)\n",
    "    \n",
    "# Replace Grand Princess as From Grand Princess\n",
    "if 'Grand Princess' in list(US_data['Province/State']):\n",
    "    US_data['Province/State'].replace({'Grand Princess':'From Grand Princess'}, inplace=True)\n",
    "    \n",
    "# Replace Diamond Princess as From Diamond Princess cruise\n",
    "if 'Diamond Princess' in list(US_data['Province/State']):\n",
    "    US_data['Province/State'].replace({'Diamond Princess':'From Diamond Princess cruise'}, inplace=True)\n",
    "    \n",
    "# Assign 0 in column Province/State as unassigned\n",
    "if 0 in list(US_data['Province/State']):\n",
    "    US_data.at[US_data.loc[US_data['Province/State'] == 0,].index, 'Province/State'] = 'Unassigned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# US_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Locations = []\n",
    "Confirmed = []\n",
    "Recovered = []\n",
    "Deaths = []\n",
    "list1 = range(0, len(html_soup2.find_all('span', class_=CANindex))-4, 5)\n",
    "list2 = range(1, len(html_soup2.find_all('span', class_=CANindex))-3, 5)\n",
    "list3 = range(2, len(html_soup2.find_all('span', class_=CANindex))-2, 5)\n",
    "list4 = range(3, len(html_soup2.find_all('span', class_=CANindex))-1, 5)\n",
    "\n",
    "for index in list1:\n",
    "    if len(html_soup2.find_all('span', class_=CANindex)[index].contents):\n",
    "        Locations.append(html_soup2.find_all('span', class_=CANindex)[index].contents[0])\n",
    "    else:\n",
    "        Locations.append(0)\n",
    "for index in list2:\n",
    "    if len(html_soup2.find_all('span', class_=CANindex)[index].contents):\n",
    "        Confirmed.append(html_soup2.find_all('span', class_=CANindex)[index].contents[0])\n",
    "    else:\n",
    "        Confirmed.append(0)\n",
    "for index in list3:\n",
    "    #. They do not provide recovered cases number\n",
    "    #if len(html_soup2.find_all('span', class_=CANindex)[index].contents):\n",
    "    #    Recovered.append(html_soup2.find_all('span', class_=CANindex)[index].contents[0])\n",
    "    #else:\n",
    "    Recovered.append(0)\n",
    "for index in list3:\n",
    "    if len(html_soup2.find_all('span', class_=CANindex)[index].contents):\n",
    "        Deaths.append(html_soup2.find_all('span', class_=CANindex)[index].contents[0])\n",
    "    else:\n",
    "        Deaths.append(0)\n",
    "    \n",
    "CAN_data = pd.DataFrame({'Province/State':Locations,\n",
    "                         'Confirmed':Confirmed,\n",
    "                         'Deaths':Deaths,\n",
    "                         #'Recovered':Recovered,  \n",
    "                            })\n",
    "\n",
    "# Remove rows that are not data\n",
    "CAN_data.drop(CAN_data[CAN_data['Deaths'] == 'Deaths'].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAN_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_Can_data = pd.concat([US_data, CAN_data], ignore_index=True)\n",
    "US_Can_data = US_Can_data.apply(lambda x: x.str.strip())\n",
    "# US_Can_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nameList = pd.read_csv('../data/web_data/statesNameTranslation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "US_Can_data_EN = pd.merge(US_Can_data, nameList, how = 'left', left_on = 'Province/State', right_on = 'English')\n",
    "US_Can_data_EN = US_Can_data_EN.drop(['Chinese', 'Province/State', 'Abbr.'], axis=1)\n",
    "US_Can_data_EN['Last Update'] = lastUpdateTime[1:]\n",
    "US_Can_data_EN.rename(columns={'English':'Province/State'}, inplace=True)\n",
    "US_Can_data_EN = US_Can_data_EN.drop(US_Can_data_EN[US_Can_data_EN['Province/State'] == 'Wuhan Evacuee'].index, axis=0)\n",
    "columnOrder = ['Province/State', 'Country/Region', 'Last Update','Confirmed', 'Deaths', 'Recovered']\n",
    "\n",
    "# US_Can_data_EN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# China Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if we can scrap info from worldometers\n",
    "# The communication with website is ok if the response is 200\n",
    "CHN = \"https://ncov.dxy.cn/ncovh5/view/pneumonia?scene=2&clicktime=1579582238&enterid=1579582238&from=singlemessage&isappinstalled=0\"\n",
    "response3 = get(CHN, headers=headers)\n",
    "response3.encoding='utf-8' ##去掉这句则乱码，加上则正常显示，其中utf-8是根据网页源代码中设置的编码格式来指定的  \n",
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap all content from the website\n",
    "html_soup3 = BeautifulSoup(response3.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(html_soup3.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_soup3.find_all('script', id='getAreaStat')[0].contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"provinceName\":\"湖北省\",\"provinceShortName\":\"湖北\",\"currentConfirmedCount\":19568,\"confirmedCount\":67707,\"suspectedCount\":0,\"curedCount\":45153,\"deadCount\":2986,\"comment\":\"\",\"locationId\":420000,\"statisticsData\":\"https://file1.dxycdn.com/2020/0223/618/3398299751673487511-135.json\",\"cities\":[{\"cityName\":\"武汉\",\"currentConfirmedCount\":17634,\"confirmedCount\":49912,\"suspectedCount\":0,\"curedCount\":29908,\"deadCount\":2370,\"locationId\":420100},{\"cityName\":\"孝感\",\"currentConfirmedCount\":369,\"confirmedCount\":3518,\"suspectedCount\":0,\"curedCount\":3024,\"deadCount\":125,\"locationId\":420900},{\"cityName\":\"鄂州\",\"currentConfirmedCount\":352,\"confirmedCount\":1394,\"suspectedCount\":0,\"curedCount\":988,\"deadCount\":54,\"locationId\":420700},{\"cityName\":\"随州\",\"currentConfirmedCount\":187,\"confirmedCount\":1307,\"suspectedCount\":0,\"curedCount\":1077,\"deadCount\":43,\"locationId\":421300},{\"cityName\":\"宜昌\",\"currentConfirmedCount\":170,\"confirmedCount\":931,\"suspectedCount\":0,\"curedCount\":727,\"deadCount\":34,\"locationId\":420500},{\"cityName\":\"荆州\",\"currentConfirmedCount\":155,\"confirmedCount\":1580,\"suspectedCount\":0,\"curedCount\":1376,\"deadCount\":49,\"locationId\":421000},{\"cityName\":\"黄冈\",\"currentConfirmedCount\":151,\"confirmedCount\":2907,\"suspectedCount\":0,\"curedCount\":2631,\"deadCount\":125,\"locationId\":421100},{\"cityName\":\"荆门\",\"currentConfirmedCount\":146,\"confirmedCount\":928,\"suspectedCount\":0,\"curedCount\":743,\"deadCount\":39,\"locationId\":420800},{\"cityName\":\"黄石\",\"currentConfirmedCount\":95,\"confirmedCount\":1015,\"suspectedCount\":0,\"curedCount\":884,\"deadCount\":36,\"locationId\":420200},{\"cityName\":\"十堰\",\"currentConfirmedCount\":93,\"confirmedCount\":672,\"suspectedCount\":0,\"curedCount\":571,\"deadCount\":8,\"locationId\":420300},{\"cityName\":\"襄阳\",\"currentConfirmedCount\":82,\"confirmedCount\":1175,\"suspectedCount\":0,\"curedCount\":1055,\"deadCount\":38,\"locationId\":420600},{\"cityName\":\"仙桃\",\"currentConfirmedCount\":53,\"confirmedCount\":575,\"suspectedCount\":0,\"curedCount\":501,\"deadCount\":21,\"locationId\":429004},{\"cityName\":\"天门\",\"currentConfirmedCount\":24,\"confirmedCount\":496,\"suspectedCount\":0,\"curedCount\":457,\"deadCount\":15,\"locationId\":429006},{\"cityName\":\"咸宁\",\"currentConfirmedCount\":21,\"confirmedCount\":836,\"suspectedCount\":0,\"curedCount\":801,\"deadCount\":14,\"locationId\":421200},{\"cityName\":\"潜江\",\"currentConfirmedCount\":21,\"confirmedCount\":198,\"suspectedCount\":0,\"curedCount\":168,\"deadCount\":9,\"locationId\":429005},{\"cityName\":\"恩施州\",\"currentConfirmedCount\":15,\"confirmedCount\":252,\"suspectedCount\":0,\"curedCount\":231,\"deadCount\":6,\"locationId\":422800},{\"cityName\":\"神农架林区\",\"currentConfirmedCount\":0,\"confirmedCount\":11,\"suspectedCount\":0,\"curedCount\":11,\"deadCount\":0,\"locationId\":429021}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
